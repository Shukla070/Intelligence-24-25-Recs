{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3b36545",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-10-10T19:56:23.066150Z",
     "iopub.status.busy": "2024-10-10T19:56:23.065297Z",
     "iopub.status.idle": "2024-10-10T19:56:24.250715Z",
     "shell.execute_reply": "2024-10-10T19:56:24.249845Z"
    },
    "papermill": {
     "duration": 1.194478,
     "end_time": "2024-10-10T19:56:24.253077",
     "exception": false,
     "start_time": "2024-10-10T19:56:23.058599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "404e0782",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-10T19:56:24.264038Z",
     "iopub.status.busy": "2024-10-10T19:56:24.263641Z",
     "iopub.status.idle": "2024-10-10T19:56:31.709623Z",
     "shell.execute_reply": "2024-10-10T19:56:31.708796Z"
    },
    "papermill": {
     "duration": 7.453767,
     "end_time": "2024-10-10T19:56:31.711937",
     "exception": false,
     "start_time": "2024-10-10T19:56:24.258170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29311eba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-10T19:56:31.722769Z",
     "iopub.status.busy": "2024-10-10T19:56:31.722352Z",
     "iopub.status.idle": "2024-10-10T19:56:31.727494Z",
     "shell.execute_reply": "2024-10-10T19:56:31.726724Z"
    },
    "papermill": {
     "duration": 0.012507,
     "end_time": "2024-10-10T19:56:31.729351",
     "exception": false,
     "start_time": "2024-10-10T19:56:31.716844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the forward diffusion process with proper broadcasting\n",
    "def forward_diffusion(x0, noise, t, T):\n",
    "    \"\"\"\n",
    "    Applies the forward diffusion process with proper broadcasting.\n",
    "    \n",
    "    Args:\n",
    "    - x0: Original image tensor (batch_size, channels, height, width)\n",
    "    - noise: Gaussian noise tensor with the same shape as x0\n",
    "    - t: Current time step in the diffusion process (1D tensor of size [batch_size])\n",
    "    - T: Total number of time steps\n",
    "    \n",
    "    Returns:\n",
    "    - xt: Noised image tensor at time step t\n",
    "    \"\"\"\n",
    "    \n",
    "    alpha = 1 - (t.view(-1, 1, 1, 1) / T)  # broadcasting\n",
    "    return alpha * x0 + (1 - alpha) * noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d24b0bb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-10T19:56:31.739766Z",
     "iopub.status.busy": "2024-10-10T19:56:31.739448Z",
     "iopub.status.idle": "2024-10-10T19:56:31.746415Z",
     "shell.execute_reply": "2024-10-10T19:56:31.745584Z"
    },
    "papermill": {
     "duration": 0.0142,
     "end_time": "2024-10-10T19:56:31.748234",
     "exception": false,
     "start_time": "2024-10-10T19:56:31.734034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# UNet model for reverse diffusion (denoising)\n",
    "class SimpleUNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(SimpleUNet, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, out_channels, kernel_size=3, padding=1),\n",
    "            nn.Sigmoid()  \n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d574672",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-10T19:56:31.758735Z",
     "iopub.status.busy": "2024-10-10T19:56:31.758063Z",
     "iopub.status.idle": "2024-10-10T19:56:31.762275Z",
     "shell.execute_reply": "2024-10-10T19:56:31.761513Z"
    },
    "papermill": {
     "duration": 0.011235,
     "end_time": "2024-10-10T19:56:31.764048",
     "exception": false,
     "start_time": "2024-10-10T19:56:31.752813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "T = 1000  # Number of time steps\n",
    "batch_size = 32\n",
    "learning_rate = 1e-4\n",
    "epochs = 15\n",
    "img_size = (128, 128) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b230bf58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-10T19:56:31.775371Z",
     "iopub.status.busy": "2024-10-10T19:56:31.775106Z",
     "iopub.status.idle": "2024-10-10T19:56:31.782202Z",
     "shell.execute_reply": "2024-10-10T19:56:31.781440Z"
    },
    "papermill": {
     "duration": 0.01542,
     "end_time": "2024-10-10T19:56:31.784115",
     "exception": false,
     "start_time": "2024-10-10T19:56:31.768695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define dataset loading function for underwater images\n",
    "class UnderwaterDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, raw_folder, reference_folder, transform=None):\n",
    "        self.raw_images = [os.path.join(raw_folder, img) for img in os.listdir(raw_folder)]\n",
    "        self.reference_images = [os.path.join(reference_folder, img) for img in os.listdir(reference_folder)]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.raw_images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        raw_image = Image.open(self.raw_images[idx]).convert(\"RGB\")\n",
    "        reference_image = Image.open(self.reference_images[idx]).convert(\"RGB\")\n",
    "        \n",
    "        if self.transform:\n",
    "            raw_image = self.transform(raw_image)\n",
    "            reference_image = self.transform(reference_image)\n",
    "        \n",
    "        return raw_image, reference_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c4d3082",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-10T19:56:31.794231Z",
     "iopub.status.busy": "2024-10-10T19:56:31.793975Z",
     "iopub.status.idle": "2024-10-10T19:56:31.798241Z",
     "shell.execute_reply": "2024-10-10T19:56:31.797400Z"
    },
    "papermill": {
     "duration": 0.011566,
     "end_time": "2024-10-10T19:56:31.800216",
     "exception": false,
     "start_time": "2024-10-10T19:56:31.788650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define transformations for underwater images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cc90680",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-10T19:56:31.810513Z",
     "iopub.status.busy": "2024-10-10T19:56:31.810259Z",
     "iopub.status.idle": "2024-10-10T19:56:31.814116Z",
     "shell.execute_reply": "2024-10-10T19:56:31.813313Z"
    },
    "papermill": {
     "duration": 0.010946,
     "end_time": "2024-10-10T19:56:31.815976",
     "exception": false,
     "start_time": "2024-10-10T19:56:31.805030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Paths to training and testing dataset folders\n",
    "train_raw_folder = '/kaggle/input/wec-task-2/Train/Raw'\n",
    "train_reference_folder = '/kaggle/input/wec-task-2/Train/Reference'\n",
    "test_raw_folder = '/kaggle/input/wec-task-2/Test/Raw'\n",
    "test_reference_folder = '/kaggle/input/wec-task-2/Test/Reference'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbc734b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-10T19:56:31.826057Z",
     "iopub.status.busy": "2024-10-10T19:56:31.825781Z",
     "iopub.status.idle": "2024-10-10T19:56:31.979059Z",
     "shell.execute_reply": "2024-10-10T19:56:31.978347Z"
    },
    "papermill": {
     "duration": 0.16046,
     "end_time": "2024-10-10T19:56:31.981001",
     "exception": false,
     "start_time": "2024-10-10T19:56:31.820541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load training and testing datasets\n",
    "train_dataset = UnderwaterDataset(train_raw_folder, train_reference_folder, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca366977",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-10T19:56:31.991800Z",
     "iopub.status.busy": "2024-10-10T19:56:31.991043Z",
     "iopub.status.idle": "2024-10-10T19:56:32.283563Z",
     "shell.execute_reply": "2024-10-10T19:56:32.282777Z"
    },
    "papermill": {
     "duration": 0.300149,
     "end_time": "2024-10-10T19:56:32.285814",
     "exception": false,
     "start_time": "2024-10-10T19:56:31.985665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model, optimizer, loss\n",
    "model = SimpleUNet(in_channels=3, out_channels=3)  \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e313655a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-10T19:56:32.296526Z",
     "iopub.status.busy": "2024-10-10T19:56:32.296241Z",
     "iopub.status.idle": "2024-10-10T20:06:03.379016Z",
     "shell.execute_reply": "2024-10-10T20:06:03.373748Z"
    },
    "papermill": {
     "duration": 571.093442,
     "end_time": "2024-10-10T20:06:03.384085",
     "exception": false,
     "start_time": "2024-10-10T19:56:32.290643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15, Loss: 0.06085292622447014\n",
      "Epoch 2/15, Loss: 0.05511225387454033\n",
      "Epoch 3/15, Loss: 0.04923778027296066\n",
      "Epoch 4/15, Loss: 0.04560481384396553\n",
      "Epoch 5/15, Loss: 0.039505694061517715\n",
      "Epoch 6/15, Loss: 0.04550008103251457\n",
      "Epoch 7/15, Loss: 0.045904383063316345\n",
      "Epoch 8/15, Loss: 0.04249816760420799\n",
      "Epoch 9/15, Loss: 0.035655662417411804\n",
      "Epoch 10/15, Loss: 0.047562986612319946\n",
      "Epoch 11/15, Loss: 0.040187086910009384\n",
      "Epoch 12/15, Loss: 0.03946516662836075\n",
      "Epoch 13/15, Loss: 0.03942451253533363\n",
      "Epoch 14/15, Loss: 0.04312475770711899\n",
      "Epoch 15/15, Loss: 0.03772418200969696\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Apply forward diffusion (add noise)\n",
    "        noise = torch.randn_like(data)\n",
    "        t = torch.randint(0, T, (data.shape[0],)).to(device)  # Random time steps\n",
    "        xt = forward_diffusion(data, noise, t, T)\n",
    "        \n",
    "        # Denoising step: predict original image from noisy image\n",
    "        reconstructed = model(xt)\n",
    "        loss = criterion(reconstructed, target)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch {epoch + 1}/{epochs}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5fc29ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-10T20:06:03.399762Z",
     "iopub.status.busy": "2024-10-10T20:06:03.399059Z",
     "iopub.status.idle": "2024-10-10T20:06:03.446539Z",
     "shell.execute_reply": "2024-10-10T20:06:03.445647Z"
    },
    "papermill": {
     "duration": 0.057653,
     "end_time": "2024-10-10T20:06:03.448592",
     "exception": false,
     "start_time": "2024-10-10T20:06:03.390939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Testing and generating enhanced images\n",
    "test_dataset = UnderwaterDataset(test_raw_folder, test_reference_folder, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6212969",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-10T20:06:03.463948Z",
     "iopub.status.busy": "2024-10-10T20:06:03.463264Z",
     "iopub.status.idle": "2024-10-10T20:06:05.371391Z",
     "shell.execute_reply": "2024-10-10T20:06:05.370441Z"
    },
    "papermill": {
     "duration": 1.918351,
     "end_time": "2024-10-10T20:06:05.373724",
     "exception": false,
     "start_time": "2024-10-10T20:06:03.455373",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "# Function to compute MSE\n",
    "def compute_mse(pred, target):\n",
    "    return F.mse_loss(pred, target).item()\n",
    "\n",
    "# Function to compute PSNR and SSIM\n",
    "def compute_psnr_ssim(pred, target):\n",
    "    # Convert from PyTorch tensors to NumPy arrays for skimage metrics\n",
    "    pred = pred.cpu().numpy().transpose(1, 2, 0)  # Convert to HWC\n",
    "    target = target.cpu().numpy().transpose(1, 2, 0)\n",
    "    \n",
    "    # Compute PSNR\n",
    "    psnr_value = psnr(target, pred, data_range=1.0)\n",
    "    \n",
    "    # Compute SSIM (for RGB images, we set multichannel=True)\n",
    "    ssim_value = ssim(target, pred, multichannel=True, data_range=1.0, win_size=3)\n",
    "    \n",
    "    return psnr_value, ssim_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5315efe3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-10T20:06:05.386882Z",
     "iopub.status.busy": "2024-10-10T20:06:05.386411Z",
     "iopub.status.idle": "2024-10-10T20:06:21.897032Z",
     "shell.execute_reply": "2024-10-10T20:06:21.895408Z"
    },
    "papermill": {
     "duration": 16.519377,
     "end_time": "2024-10-10T20:06:21.899050",
     "exception": false,
     "start_time": "2024-10-10T20:06:05.379673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average PSNR: 16.30504430366424\n",
      "Average MSE: 0.02973171222072683\n",
      "Average SSIM: 0.4945477907704117\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Directory to save the enhanced images\n",
    "output_dir = 'enhanced_images/'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save function to convert tensor to image and save\n",
    "def save_image(tensor, file_path):\n",
    "    \"\"\"\n",
    "    Convert a PyTorch tensor to an image and save it to disk.\n",
    "    \n",
    "    Args:\n",
    "    - tensor: PyTorch tensor of shape (C, H, W)\n",
    "    - file_path: File path to save the image\n",
    "    \"\"\"\n",
    "    # Convert to numpy array and denormalize (if needed)\n",
    "    image_np = tensor.cpu().numpy().transpose(1, 2, 0)  # Convert to HWC\n",
    "    image_np = (image_np * 255).astype(np.uint8)  # Scale from [0, 1] to [0, 255]\n",
    "    \n",
    "    # Convert to a PIL image and save\n",
    "    image_pil = Image.fromarray(image_np)\n",
    "    image_pil.save(file_path)\n",
    "\n",
    "# Testing and saving enhanced images\n",
    "model.eval()\n",
    "psnr_scores, mse_scores, ssim_scores = [], [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (raw_images, reference_images) in enumerate(test_loader):\n",
    "        raw_images, reference_images = raw_images.to(device), reference_images.to(device)\n",
    "        \n",
    "        # Generate enhanced images by denoising\n",
    "        enhanced_images = model(raw_images)\n",
    "        \n",
    "        # Save each enhanced image\n",
    "        for i in range(enhanced_images.shape[0]):\n",
    "            enhanced_image = enhanced_images[i]\n",
    "            reference_image = reference_images[i]\n",
    "            \n",
    "            # Save the enhanced image to disk\n",
    "            save_path = os.path.join(output_dir, f\"enhanced_image_{batch_idx}_{i}.png\")\n",
    "            save_image(enhanced_image, save_path)\n",
    "            \n",
    "            # Compute MSE\n",
    "            mse_value = compute_mse(enhanced_image, reference_image)\n",
    "            mse_scores.append(mse_value)\n",
    "            \n",
    "            # Compute PSNR and SSIM\n",
    "            psnr_value, ssim_value = compute_psnr_ssim(enhanced_image, reference_image)\n",
    "            psnr_scores.append(psnr_value)\n",
    "            ssim_scores.append(ssim_value)\n",
    "\n",
    "# Calculate the average scores\n",
    "avg_psnr = np.mean(psnr_scores)\n",
    "avg_mse = np.mean(mse_scores)\n",
    "avg_ssim = np.mean(ssim_scores)\n",
    "\n",
    "print(f\"Average PSNR: {avg_psnr}\")\n",
    "print(f\"Average MSE: {avg_mse}\")\n",
    "print(f\"Average SSIM: {avg_ssim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6679ef1b",
   "metadata": {
    "papermill": {
     "duration": 0.005778,
     "end_time": "2024-10-10T20:06:21.910859",
     "exception": false,
     "start_time": "2024-10-10T20:06:21.905081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5826927,
     "sourceId": 9561737,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 605.358999,
   "end_time": "2024-10-10T20:06:24.766080",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-10T19:56:19.407081",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
